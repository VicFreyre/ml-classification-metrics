
# üêç Avalia√ß√£o de Modelos de Classifica√ß√£o: M√©tricas e Implementa√ß√£o em Python 

## 1. Introdu√ß√£o
A avalia√ß√£o de modelos de classifica√ß√£o √© essencial para medir a qualidade das previs√µes. Essa an√°lise √© baseada na **matriz de confus√£o**, composta pelos seguintes elementos:

- **Verdadeiros Positivos (VP):** Casos positivos corretamente classificados.
- **Verdadeiros Negativos (VN):** Casos negativos corretamente classificados.
- **Falsos Positivos (FP):** Casos negativos incorretamente previstos como positivos.
- **Falsos Negativos (FN):** Casos positivos incorretamente previstos como negativos.

<img width="1093" height="507" alt="image" src="https://github.com/user-attachments/assets/7a61eb51-d76b-42df-8032-1637a03a042c" />

Execute o modelo pelo [Google Colab](https://colab.research.google.com/drive/1FWQuTgwRWB7lslvNlbtoeCgisOpmLh5R#scrollTo=Tu3UAuvVP3Bb)


---

## 2. M√©tricas de Avalia√ß√£o

- **Sensibilidade (Recall):**  
  Propor√ß√£o de positivos reais corretamente identificados pelo modelo.  
  Sensibilidade = VP / (VP + FN)

- **Especificidade:**  
  Propor√ß√£o de negativos corretamente identificados.  
  Especificidade = VN / (VN + FP)

- **Acur√°cia:**  
  Propor√ß√£o de todas as previs√µes corretas.  
  Acur√°cia = (VP + VN) / (VP + VN + FP + FN)

- **Precis√£o (Precision):**  
  Propor√ß√£o de previs√µes positivas que s√£o realmente positivas.  
  Precis√£o = VP / (VP + FP)

- **F-score:**  
  M√©dia harm√¥nica entre precis√£o e sensibilidade.  
  F-score = 2 √ó (Precis√£o √ó Sensibilidade) / (Precis√£o + Sensibilidade)

**Legenda:**  
- `VP` = Verdadeiros Positivos  
- `VN` = Verdadeiros Negativos  
- `FP` = Falsos Positivos  
- `FN` = Falsos Negativos
